import streamlit as st
import io
import json
from google.oauth2 import service_account
from google.cloud import speech
import google.generativeai as genai
from googleapiclient.discovery import build
from datetime import datetime

# ==========================================
# âš™ï¸ ì„¤ì • (í´ë¼ìš°ë“œ ë³´ì•ˆ ê¸ˆê³  + ì˜¤ë¥˜ ë°©ì§€ ì²˜ë¦¬)
# ==========================================
try:
    # 1. Secretsì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    gcp_info = dict(st.secrets["gcp_service_account"])
    
    # ğŸš¨ ì¤‘ìš”: private_keyì˜ ì¤„ë°”ê¿ˆ ë¬¸ì(\n)ê°€ ê¹¨ì§€ëŠ” ë¬¸ì œ ìë™ í•´ê²°
    if "private_key" in gcp_info:
        gcp_info["private_key"] = gcp_info["private_key"].replace("\\n", "\n")

    GOOGLE_API_KEY = st.secrets["general"]["GOOGLE_API_KEY"]
    SHARED_DRIVE_ID = st.secrets["general"]["SHARED_DRIVE_ID"]
    AI_MODEL_NAME = 'gemini-2.0-flash'

except Exception as e:
    st.error(f"ğŸš¨ ë³´ì•ˆ ì„¤ì •(Secrets) ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

# ==========================================
# ğŸ› ï¸ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ==========================================
def step1_transcribe(uploaded_file):
    # íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì½ìŒ
    content = uploaded_file.read()
    
    creds = service_account.Credentials.from_service_account_info(gcp_info)
    client = speech.SpeechClient(credentials=creds)

    audio = speech.RecognitionAudio(content=content)
    
    # â˜… ìˆ˜ì •ë¨: encodingê³¼ sample_rate_hertzë¥¼ ì§€ì›Œì„œ êµ¬ê¸€ì´ 'ìë™ ê°ì§€'í•˜ê²Œ ë§Œë“¦
    config = speech.RecognitionConfig(
        language_code="ko-KR",
        enable_automatic_punctuation=True,
        # mp3ë‚˜ ìŠ¤ë§ˆíŠ¸í° ë…¹ìŒ íŒŒì¼ í˜¸í™˜ì„±ì„ ìœ„í•´ ìë™ ê°ì§€ ëª¨ë“œë¡œ ë³€ê²½
        diarization_config=speech.SpeakerDiarizationConfig(
            enable_speaker_diarization=True,
            min_speaker_count=2,
            max_speaker_count=5,
        ),
    )
    
    # 10MB ì´ìƒì˜ íŒŒì¼ì€ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
    try:
        operation = client.long_running_recognize(config=config, audio=audio)
        response = operation.result(timeout=600)
    except Exception as e:
        st.error(f"âŒ ë…¹ìŒ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.warning("ğŸ’¡ íŒíŠ¸: íŒŒì¼ ìš©ëŸ‰ì´ 10MB(ì•½ 10ë¶„)ë³´ë‹¤ í¬ë©´ êµ¬ê¸€ ì •ì±…ìƒ ì²˜ë¦¬ê°€ ì•ˆ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§§ì€ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")
        st.stop()

    transcript_text = ""
    # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°(ë§ì´ ì—†ëŠ” ê²½ìš°) ì²˜ë¦¬
    if not response.results:
        return "ëŒ€í™” ë‚´ìš©ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    result = response.results[-1]
    
    # alternativesê°€ ìˆëŠ”ì§€ í™•ì¸
    if not result.alternatives:
        return "ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    words_info = result.alternatives[0].words

    current_speaker = None
    sentence_buffer = []

    for word_info in words_info:
        speaker_tag = word_info.speaker_tag
        if current_speaker != speaker_tag:
            if current_speaker is not None:
                line = f"[í™”ì {current_speaker}]: {' '.join(sentence_buffer)}"
                transcript_text += line + "\n"
            current_speaker = speaker_tag
            sentence_buffer = []
        sentence_buffer.append(word_info.word)
    
    if sentence_buffer:
        line = f"[í™”ì {current_speaker}]: {' '.join(sentence_buffer)}"
        transcript_text += line + "\n"

    return transcript_text

def step2_summarize(transcript):
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel(AI_MODEL_NAME)
    prompt = f"""
    ë‹¹ì‹ ì€ KCH Globalì˜ ìœ ëŠ¥í•œ íšŒì˜ë¡ ì„œê¸°ì…ë‹ˆë‹¤.
    ì•„ë˜ ë…¹ì·¨ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
    
    [ë…¹ì·¨ë¡]
    {transcript}
    
    [ì‘ì„± ì–‘ì‹]
    # ğŸ“… íšŒì˜ ìš”ì•½ ë³´ê³ ì„œ
    ## 1. í•µì‹¬ ì•ˆê±´
    ## 2. ì£¼ìš” ë…¼ì˜ ì‚¬í•­
    ## 3. ê²°ì • ì‚¬í•­
    ## 4. í–¥í›„ ê³„íš (ë‹´ë‹¹ì ì§€ì •)
    """
    response = model.generate_content(prompt)
    return response.text

def step3_save(summary, transcript):
    SCOPES = ['https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/documents']
    creds = service_account.Credentials.from_service_account_info(gcp_info, scopes=SCOPES)
    drive_service = build('drive', 'v3', credentials=creds)
    docs_service = build('docs', 'v1', credentials=creds)

    today = datetime.now().strftime("%Y-%m-%d %Hì‹œ%Më¶„")
    file_name = f"[AIíšŒì˜ë¡] {today} íšŒì˜ ê²°ê³¼"

    file_metadata = {
        'name': file_name,
        'mimeType': 'application/vnd.google-apps.document',
        'parents': [SHARED_DRIVE_ID]
    }
    file = drive_service.files().create(body=file_metadata, fields='id', supportsAllDrives=True).execute()
    doc_id = file.get('id')

    full_content = summary + "\n\n" + "-"*30 + "\n[ì°¸ê³ : ëŒ€í™” ì›ë³¸]\n" + transcript
    requests = [{'insertText': {'location': {'index': 1}, 'text': full_content}}]
    docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()
    return file_name

# ==========================================
# ğŸ–¥ï¸ í™”ë©´ êµ¬ì„±
# ==========================================
st.set_page_config(page_title="KCH Global AI íšŒì˜ë¡", page_icon="ğŸ™ï¸")
st.title("ğŸ™ï¸ KCH Global AI íšŒì˜ë¡ ìƒì„±ê¸°")
st.markdown("ì–¸ì œ ì–´ë””ì„œë‚˜ ë…¹ìŒ íŒŒì¼ë§Œ ì˜¬ë¦¬ì„¸ìš”. **AIê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.**")

# íŒŒì¼ ì—…ë¡œë” (ìš©ëŸ‰ ì œí•œ ì•ˆë‚´ ì¶”ê°€)
uploaded_file = st.file_uploader("ë…¹ìŒ íŒŒì¼ ì—…ë¡œë“œ (MP3, WAV ê¶Œì¥)", type=["mp3", "wav", "m4a"])

if uploaded_file is not None:
    st.audio(uploaded_file)
    if st.button("ğŸš€ íšŒì˜ë¡ ë§Œë“¤ê¸° ì‹œì‘"):
        with st.status("í´ë¼ìš°ë“œ ì„œë²„ì—ì„œ ì‘ì—… ì¤‘... (3~5ë¶„ ì†Œìš”)", expanded=True) as status:
            
            st.write("ğŸ§ 1ë‹¨ê³„: ë°›ì•„ì“°ê¸° ì¤‘...")
            transcript = step1_transcribe(uploaded_file)
            st.write("âœ… ë°›ì•„ì“°ê¸° ì™„ë£Œ!")
            
            st.write("ğŸ§  2ë‹¨ê³„: ìš”ì•½ ì¤‘...")
            summary = step2_summarize(transcript)
            st.write("âœ… ìš”ì•½ ì™„ë£Œ!")
            
            st.write("ğŸ’¾ 3ë‹¨ê³„: ì €ì¥ ì¤‘...")
            file_name = step3_save(summary, transcript)
            
            status.update(label="ğŸ‰ ì™„ë£Œ!", state="complete", expanded=False)

        st.success(f"'{file_name}' ì €ì¥ ì™„ë£Œ!")
        st.subheader("ë¯¸ë¦¬ë³´ê¸°")
        st.markdown(summary)
